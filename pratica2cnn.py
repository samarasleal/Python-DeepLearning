# -*- coding: utf-8 -*-
"""pratica2CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rXINtM2fSQsAhLrNbDN3YQLJ3EnAD-s4
"""

# Carregando os dados
import tensorflow as tf
import matplotlib.pyplot as plt
(x_treino, y_treino), (x_teste, y_teste) = tf.keras.datasets.mnist.load_data()

# Visualização dos dados
for i in range(5):
  plt.subplot(1, 5, i+1)
  plt.subplot(1, 5, i+1)
  plt.tight_layout()
  plt.imshow(x_treino[i].reshape(28, 28), cmap='gray')
  plt.title('Rótulo:{}'.format(y_treino[i]))
  plt.xticks([])
  plt.yticks([])
plt.show()

# Separação do conjunto de dados: Treinamento, validação e teste
import numpy as np
 
quantidade_dados_treino = 55000
 
x_validacao = x_treino[quantidade_dados_treino:, ..., np.newaxis]
y_validacao = y_treino[quantidade_dados_treino:]
x_treino = x_treino[:quantidade_dados_treino, ..., np.newaxis]
y_treino = y_treino[:quantidade_dados_treino]
 
x_teste =  x_teste[..., np.newaxis]
 
print('Formato da Imagem:{}'.format(x_treino[0].shape), end = '\n')
print('Conjunto de Treinamento:{} registros'.format(len(x_treino)))
print('Conjunto de Validação:{}registros'.format(len(x_validacao)))
print('Conjunto de Testes:      {} registros'.format(len(x_teste)))

# Preenchimento (padding) dos dados de entrada: precisamos fazer um ajuste nos dados de entrada. 
# A camada de entrada da arquitetura LeNet-5 consiste em imagens com dimensões de 32 × 32. 
# As imagens do MNIST têm dimensões 28 × 28, precisamos preencher a entrada com zeros (0) a fim de torná-la 32 × 32. 
x_treino = np.pad(x_treino, ((0,0),(2,2),(2,2),(0,0)), 'constant')
x_validacao = np.pad(x_validacao, ((0,0),(2,2),(2,2),(0,0)), 'constant')
x_teste = np.pad(x_teste, ((0,0),(2,2),(2,2),(0,0)), 'constant')
 
print('Informações sobre as mudanças dos dados de entrada: ', end='\n\n')
print('Conjunto de treinamento: {}'.format(x_treino.shape))
print('Conjunto de Validação: {}'.format(x_validacao.shape))
print('Conjunto de Testes: {}'.format(x_teste.shape))

# Normalização dos dados
# Os dados de entrada do MNIST estão em escalas de cinza, ou seja, vão de 0 a 255. 
# Então vamos transformá-los para dados no intervalo de 0 a 1. Para isso, basta dividirmos os valores das variáveis por 255.
normalizar_dados = lambda t: t/255
x_treino = normalizar_dados(x_treino)
x_validacao = normalizar_dados(x_validacao)
x_teste = normalizar_dados(x_teste)

# Arquitetura LeNet
# A LeNet tem 8 camadas: 1 de entrada, 3 de convolução, 2 de aglomeração (pooling) e 2 totalmente conectadas, sendo uma delas a de saída.
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Conv2D, AveragePooling2D, Flatten, Dense
 
def arquitetura_LeNet_5(funcao_ativacao):
    modelo = Sequential()
 
    modelo.add(Conv2D(6, kernel_size=(5, 5), 
                        strides=(1, 1), 
                        activation=funcao_ativacao, 
                        input_shape=(32,32,1), 
                        padding='valid'))
 
    modelo.add(AveragePooling2D(pool_size=(2, 2), 
                                 strides=(2, 2), 
                                 padding='valid'))
 
    modelo.add(Conv2D(16, kernel_size=(5, 5), 
                         strides=(1, 1), 
                         activation=funcao_ativacao, 
                         padding='valid'))
 
    modelo.add(AveragePooling2D(pool_size=(2, 2), 
                                 strides=(2, 2), 
                                 padding='valid'))
 
    modelo.add(Conv2D(120, kernel_size=(1, 1), 
                         strides=(1, 1), 
                         activation=funcao_ativacao, 
                         padding='valid'))
 
    modelo.add(Flatten())
 
    modelo.add(Dense(84, activation=funcao_ativacao))
 
    modelo.add(Dense(10, activation='softmax'))
     
    return modelo

# Visualização da Arquitetura do modelo
modelo = arquitetura_LeNet_5('relu')
modelo.summary()

# Treinamento do modelo
from tensorflow.keras.losses import CategoricalCrossentropy
 
modelo.compile(loss='sparse_categorical_crossentropy', 
                 optimizer='sgd', metrics=['accuracy']) 
 
quantidade_de_epocas = 10
historico_treinamento = modelo.fit(x_treino, y_treino, 
                                     validation_data=(x_validacao, y_validacao),
                                     batch_size=64, 
                                     epochs=quantidade_de_epocas)
# Salva o modelo
modelo.save('modelo_lenet5')

# Avaliação do Modelo
# Um modelo de boa qualidade vai produzir um erro próximo de zero e acurácia perto de um.
loss, accuracy = modelo.evaluate(x_teste, y_teste,batch_size=64);
print('loss:{}'.format(loss))
print('accuracy:{}'.format(accuracy))

# Predição de Dados
indice_imagem = 4567
 
predicao = modelo.predict(x_teste[indice_imagem].reshape(1,32,32,1))
 
print('Predição: {}'.format(predicao[0]), end = '\n\n')
 
print('Nosso modelo CNN prevê que o dígito na imagem é:', predicao.argmax())
plt.imshow(x_teste[indice_imagem].reshape(32,32), cmap='Greys')

# Recuperação do Modelo
modelo_recuperado = tf.keras.models.load_model('modelo_lenet5')

# Impressão do treinamento
plt.title('Cálculo do Erro ao longo do treinamento')
plt.ylabel('Erro')
plt.xlabel('Época')
 
plt.plot(historico_treinamento.history['loss'])
plt.plot(historico_treinamento.history['val_loss'])
plt.legend(['loss (treinamento)', 'val_loss (validação)'], loc='upper right')
plt.show()